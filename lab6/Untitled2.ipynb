{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1e0492-049a-4a03-93aa-762ff6fda0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80cc5a5-2ac6-449d-a2a9-458c10a448c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5357ff96-b758-403c-8b61-46c966ac11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FashionMNIST(\n",
    "    root='./data/train',\n",
    "    transform=basic_transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888305b4-9488-4b87-83ac-3999218f9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc80d0d-f949-448e-813d-0c6023f577cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items = [dataset[i] for i in range(1000)]\n",
    "xs, ys = zip(*train_items)\n",
    "\n",
    "xs = torch.stack(xs)\n",
    "xs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c08a98-b0d9-4216-a6dd-4327350e6744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = model(xs)\n",
    "embs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0043046-eb5a-46fe-b3b8-8fb05d547a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a6e358-aa4e-42bb-ad41-a3339ebd5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log embeddings\n",
    "writer.add_embedding(embs,\n",
    "                     metadata=ys,\n",
    "                     label_img=xs)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
